---
title: "Unified Uncanny Valley Data"
author: "M Schmettow"
format: docx
editor: visual
---

```{r}
library(tidyverse)
library(readxl)
library(readr)
library(haven)
library(assertthat)
options(mc.cores = 4)
library(rstanarm)
library(brms)
library(bayr)
library(uncanny)


```

# Data preparation

## Data standardization

This is a template data frame containing *an almost complete superset* of features of Uncanny Valley experiments conducted between 2016 and 2021.

-   long format, one observation per row
-   If a feature was not measured, and cannot be derived, it is set to `NA`.
-   

```{r}
UVA_0 <- tibble(
           Exp = factor(),
           Part = factor(),
           trial = numeric(),
           repetition = numeric(),
           Face = factor(),
           FaceOrigin = factor(),
           Set = factor(),
           Exposure = factor(),
           Stim = factor(), ## different stim from same face
           hum_like = numeric(),
           morph = numeric(),
           ancestoral = numeric(),
           rotation = numeric(),
           hum_skull = logical(),
           hum_eyes = logical(),
           Scale = factor(),
           Item = factor(),
           rating = numeric(),
           rt = numeric())

UV_cols <- colnames(UVA_0)
summary(UVA_0)

knitr::kable(UVA_0)
```

## Processing Data Sets

### Moll 2015

```{r}
load("Data Sets/Moll/Data/BM.Rda")

BM <- BM1 |> 
  mutate(Exp = "BM",
         Part = Participant,
         Stim = Stimulus,
         Set = "BM",
         FaceOrigin = "tech",
         trial = Trial,
         repetition = 1,
         morph = morphLevelNum,
         hum_like = NA_real_,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA_real_,
         rotation = 0,
         Exposure = Condition,
         rating = (Response - 1) /7,
         rt = RT
         ) |> 
  select(any_of(UV_cols)) |> 
  select(all_of(UV_cols))

summary(BM)
BM |> sample_n(12) |> knitr::kable()
```

### Haeske 2015

```{r}
load("Data Sets/Haeske/Data/AH.Rda")
rm(M, P)

AH_quest <- D$quest
sample_n(AH_quest, 10)

AH_part <- D$trait
sample_n(AH_part, 5)

AH_exp <- D$exp
sample_n(AH_exp, 10)

AH <- AH_exp |> 
  mutate(Exp = "AH",
         Part = Participant,
         Stim = Stimulus,
         Set = "BM",
         FaceOrigin = "tech",
         trial = Trial,
         repetition = 1,
         morph = morphLevelNum,
         hum_like = NA_real_,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA,
         rotation = 0,
         Exposure = if_else(Condition == "5s", "2000ms", "100ms"),
         rating = (response + 1)/2,
         rt = RT
         )|> 
  select(any_of(UV_cols)) |> 
  select(all_of(UV_cols))

summary(AH)

AH |> sample_n(12) |> knitr::kable()

```

### Daan Keeris

```{r}
load("Data Sets/Keeris/Data/DK.Rda")

DK <- D_$DK1 |> 
  mutate(Exp = "DK",
         #Part = Participant,
         repetition = 1,
         Stim = Stimulus,
         Set = if_else(Collection == "Mathur", "MR", "MR_DK"),
         Face = if_else(Set == "BM",
                        str_extract(Stim, "c[1-9][0-9]*"),
                        Stim),
         FaceOrigin = "tech",
         hum_like = as.numeric(if_else(Set == "MR", 
                            str_extract(Stim, "[1-9][0-9]*"), NA))/80,
         morph = morphLevel,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA,
         rotation = 0,
         Exposure = if_else(Condition == "short", "33ms", "2000ms"),
         rating = (response + 1)/2,
         rt = RT) |> 
  select(all_of(UV_cols))

summary(DK)

filter(DK, is.na(Face))

DK |> sample_n(12) |> knitr::kable()
```

### Peter Slijkhuis

```{r}
load("Data Sets/Slijkhuis/Data/PS.Pda")

PS <- PS_1 |> 
  mutate(Exp = "PS",
         Part = as.character(Part),
         Stim = Stimulus,
         Face = Stim,
         FaceOrigin = "tech",
         repetition = 1,
         morph = NA,
         hum_like = huMech,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA,
         rotation = 0,
         Exposure = str_c(as.numeric(Condition) * 1000, "ms"),
         rating = (response + 1)/2,
         rt = RT) |> 
  select(all_of(UV_cols))

summary(PS)
PS |> sample_n(12) |> knitr::kable()
```

### Robbin Koopman

```{r}
load("Data Sets/Koopman/Data/RK.Rda")

RK <- RK_1 |> 
  mutate(Exp = "RK",
         Stim = Stimulus,
         Face = Stim,
         FaceOrigin = "tech",
         trial = NA,
         repetition = repetition,
         morph = NA,
         hum_like = huMech,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA,
         rotation = 0,
         Exposure = "2000ms", # <-- check this! perhaps replace with NA or RT.
         rating = response + 1,
         rt = RT) |> 
  group_by(Part) |> 
  arrange(Obs) |> 
  mutate(trial = row_number()) |> 
  ungroup() |> 
  select(all_of(UV_cols))

summary(RK)
RK |> sample_n(12) |> knitr::kable()

```

### UV21

```{r}
#load("Data Sets/UV21/Data/BA21.Rda")
D_raw <-    
  readxl::read_excel("Data Sets/UV21/Final Dataset Uncanny Valley 16-05-21.xlsx") %>%
  filter(StartDate != "Start Date")

Stimuli <-    
  readxl::read_excel("Data Sets/UV21/Stimuli.xlsx") %>%    
  mutate(Stimulus = str_c("S", as.character(Stimulus))) %>%    
  mutate(Set = factor(Set, 1:4, labels = c("Primate", "Human", "Tri23", "RK"))) %>%         mutate(hum_like = rowMeans(select(., starts_with("H_like")), na.rm = T)) %>%
  mutate(valence = rowMeans(select(., starts_with("E_valence")), na.rm = T)) |> 
  mutate(repetition = 1) |> 
  rename(ancestoral = AncestoralCloseness) |> 
  mutate(FaceOrigin = if_else(Set == "RK",  # <---- face origin
                              "tech",
                              "bio"))

BA21 <- 
  D_raw %>%    
    select(Part = ResponseId, matches("^S\\d+")) %>%    
    pivot_longer(-Part, names_to = "Trial", values_to = "response") %>%
    filter(!is.na(response)) %>%
    separate(Trial, into = c("Stimulus", "Item", "attempt"), extra = "drop") %>%
    left_join(
      select(Stimuli, 
             Stimulus, Set, 
             valence, 
             ancestoral,
             hum_like,
             FaceOrigin), 
      by = "Stimulus") %>%
    mutate(Scale = if_else(str_detect(Item, "^2"), "Eery", "Display"),
           response  = mascutils::rescale_unit(as.numeric(response)),
           repetition = as.numeric(attempt),
           rating  = mascutils::rescale_centered(response, scale = .999),
           hum_like   = mascutils::rescale_unit(hum_like))

## almost 13,293 observations!!
BA21 |> 
  group_by(Part, Stimulus, Scale, FaceOrigin) |>
  summarize(n()) |> 
  ungroup() |> 
  dim()

UV21 <- 
  BA21 |> 
  mutate(Exp = "UV21",
         Stim = Stimulus,
         Face = Stim,
         trial = NA,
         repetition = repetition,
         morph = NA,
         hum_like = hum_like,
         hum_skull = NA,
         hum_eyes = NA,
         ancestoral = NA,
         rotation = 0,
         Exposure = "2000ms", # <-- check this! perhaps replace with NA or RT.
         Scale = if_else(Scale == "Eery",
                          "nErry",
                          Scale),
         rating = if_else(Scale == "nEeriness",
                          - ((response - 0.5) * 2)  +  1, # rescaling and reversing
                          response), 
         rt = NA) |> 
  group_by(Part) |> 
  mutate(trial = row_number()) |> 
  ungroup() |> 
  select(all_of(UV_cols))

summary(UV21)
UV21 |> sample_n(12) |> knitr::kable()
```

## Merging data sets

```{r}
UVA_1 <- 
  UVA_0 |> 
  bind_rows(BM) |> 
  bind_rows(AH) |> 
  bind_rows(DK) |> 
  bind_rows(PS) |> 
  bind_rows(RK) |> 
  bind_rows(UV21) |> 
  group_by(Exp, Part) |> 
  mutate(Part = str_c(Exp, "_", row_number())) |> 
  ungroup() |> 
  mutate(Exp = as.factor(Exp),
         Part = as.factor(Part),
         Face = as.factor(Face),
         FaceOrigin = as.factor(FaceOrigin),
         Set = as.factor(Set),
         Exposure = str_replace(Exposure, "unlimited", "2000ms"),
         Exposure = as.factor(Exposure),
         Stim = as.factor(Stim),
         Scale = as.factor(Scale),
         Item = as.factor(Item)
         ) |>
  bind_rows(UVA_0) |> 
  mutate(Exposure = forcats::lvls_reorder(Exposure, c(2,5,7,1,4,6,3))) |> 
  mutate(exposure = as.numeric(str_extract(Exposure, "[0-9]+"))/1000)

summary(UVA_1)

filter(UVA_1, Exposure == "Unlimited")

levels(UVA_1$Part)

save(UVA_1, file = "Data/UVA_1.Rda")

UVA_1 |> filter(is.na(hum_like))

```

## Checking data

```{r}
filter(UVA_1, is.na(Face))
```

```{r}
UVA_1 |>  filter(hum_like > 1)
UVA_1 |>  filter(hum_like < 0)
```

Number of participants:

```{r}
UVA_1 |> 
  select(Exp, Part) |> 
  n_distinct()
```

Number of different stimuli:

```{r}
UVA_1 |> 
  select(Stim) |> 
  n_distinct()
```

Total encounters between participants and stimuli:

```{r}
UVA_1 |> 
  select(Part, Set, Stim) |> 
  n_distinct()
```


Total observations per experiment:

```{r}
UVA_1 |> 
  group_by(Exp) |> 
  summarize(n_Obs = n()) |> 
  knitr::kable()
```


Total observations:

```{r}
dim(UVA_1)[1]
```


### Checking the ratings

```{r}
UVA_1 |> 
  group_by(Exp, Scale) |> 
  summarize(n_Resp = n(),
            n_Items = n_distinct(Item),
            n_Part = n_distinct(Part),
            n_Stim = n_distinct(Stim),
            min_rating = min(rating),
            max_rating = max(rating),
            min_hum_like = min(hum_like),
            max_hum_like = max(hum_like))

```

# Data Exploration

1.  rendering the association between *human-likeness and n-eeriness* ratings
2.  *Designometrics*: using test-retest correlations to identify  *non-compliant participants*

### Human-likeness in Robots and Eeriness ratings

Data set `UVA_2` is combining observations from all experiments with

-   *human-likeness* score compatible with Mathur & Reichlings humano-mechanical scale (huMech)
-   *nEeriness ratings* as inverted value of MacDorman's Eeriness scale.
-   with *at least 'min_obs' responses* per participant and exposure

```{r}
load("Data/UVA_1.Rda")
min_obs = 0


UVA_2 <- 
  UVA_1 |> 
  filter(Exp %in% c("DK", "PS", "RK", "UV21"),
         Scale == "nEeriness",
         !is.na(hum_like)) |> 
  group_by(Exp, Exposure, Part) |> 
  filter(n() >= min_obs) |> 
  ungroup() |> 
  rename(neeriness = rating) |> 
  bayr::as_tbl_obs()


summary(UVA_2)

save(UVA_2, file = "Data/UVA_2.Rda")
```

```{r}
UVA_2 |> filter(is.na(Face))
```

```{r}
load("Data/UVA_2.Rda")
#! fig.cap: "Sample average third degree polynomial across exposure times"
UVA_2 |> 
  ggplot(aes(x = hum_like, linetype = FaceOrigin, 
             color = as.factor(exposure), y = neeriness)) +
  facet_grid(Exp ~ "Experiments derived  from M&R 2016") +
  stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1)
```

### Universality of the UVE (long exposure)

```{r fig.width = 12, fig.height = 64}
#! fig.cap:"Participant-level third degree polynomial across exposure times"
#! fig-width: 1200
#! fig-height: 3200

UVA_2 |> 
  ggplot(aes(x = hum_like,
             line_type = FaceOrigin,
             y = neeriness)) +
  facet_wrap(~Part, ncol = 4) +
  geom_point() +
  geom_smooth(aes(color = as.factor(exposure)), 
              method = "lm", formula = y ~ poly(x, 3)) +
  ylim(0,1) +
  theme(legend.position = "top")
```

## Response times

```{r}
load("Data/UVA_2.Rda")
```


## Designometrix

### Cheater detection

In experiments with repeated participant-stimulus encounters, you would always expect a minimum of correlations between repeated ratings. Ergo, we find random-response cheaters by calculating the within-participant correlations between repetitions.

```{r}
UVA_3 <- 
  UVA_2 |> 
  filter(Exp %in% c("DK","PS","RK"),
         exposure >= .01) |> 
  select(Exp, Part, Stim, exposure, eeriness) |> 
  group_by(Part, Stim) |> 
  arrange(exposure) |>  # <--- short to long in all exps with varying exposure
  mutate(nth_exp = row_number()) |> 
  ungroup() |> 
  pivot_wider(names_from = nth_exp, 
              names_prefix = 'n_',
              values_from = eeriness)


UVA_3|> 
  group_by(Part) |>
  group_map(
    ~.x |> 
    select(n_1, n_2, n_3, n_4) |> 
    corrr::correlate(use = "pairwise.complete.obs", method = "pearson", quiet = T) |> 
    corrr::stretch()) |>
  bind_rows() |> 
  filter(r < 0.2)

```


```{r}
# library(rstanarm)

#M_0 <- lme4::lmer(eeriness ~ 1 + (1|Part) + (1|Stim) + (1|Item), data = UVA_3)

#summary(M_0)

```

# Paper 1: "The Uncanny Valley Effect: Processing speed and universality"

Almost half a century since Mori's postulation, the uncanny valley effect is still a mystery, with dozens of different theories surrounding it. In this paper, we provide an overview of the postulates to date and report on the results of an experiment that is capable of refuting a whole class of theories.
The uncanny valley effect was postulated by Mori in 197x, but without the slightest reference to psychological theories, and also without empirical evidence. With the beginning of the millennium, the uncanny valley effect gained increasing attention. In particular, the work of MacDorman, who developed a specific scale to measure the subjective experience of the effect, is worth mentioning.

Subsequently, several studies were published that primarily attempted to explain the uncanny valley effect with personality traits, such as religious beliefs. The cognitive value of these studies is limited primarily by the lack of an experimental paradigm. It was not until 2016 that Mathur and Reichling published a study that clearly and reproducibly demonstrated the effect, using both self-report measurements and behavioral observation.
To do this, the authors collected 80 images of robot faces and empirically determined the human likeness of each face. In a second experiment, subjects were asked to emotionally evaluate these faces. The relationship between human likeness and emotional response exactly reproduced the curve that Mori had postulated.
In this study, we took up both Mathur and Reichling's experiment and most of the theories postulated to date. These theories roughly fall into two categories: social-cultural, which assume the effect in acquired thought patterns, and those that assume innate cognitive mechanisms. If the origin of the effect was social-cultural, it was to be expected that it would occur for some, but not all, subjects. If, on the other hand, it was an innate cognitive effect, it should affect all subjects without exception.



## Introduction

Many theories have been proposed to explain the uncanny valley effect, which can be broadly divided into two categories: **learning-based (socialization-based) and  biological (innate) explanations**.


## Socialization

Several authors have proposed that the Uncanny Valley effect depends on the individual mind set. What a person has learned in their life time could alter the way to react to a robot face. Robot faces are cultural artifacts and as such their perception could be altered by the spectators cultural background. As stark example, humans not familiar with robots at all, would probably react much stronger and with a wide variety of emotions.

*Category conflict* theory states that the uncanny valley effect occurs when a stimulus has features that can be assigned to both human and non-human categories. This leads to *cognitive dissonance* or internal conflict as the brain tries to categorize the stimulus. The *ambiguity* and *conflicting interpretations* lead to negative emotions. Studies have shown that mixing categories, such as when a human speaks with a robot voice or vice versa, increases creepiness.

*Categorization difficulty* theory states that difficulty assigning a stimulus to a category leads to negative emotions. If an object falls between two categories (e.g. human and robot), the resulting processing difficulty can lead to a negative evaluation. However, some studies have failed to find support for this theory.

*Realism inconsistency* theory posits that the uncanny valley effect is caused by conflicting levels of realism in an object's features. For example, if some facial features are very realistic but others seem artificial, this will lead to conflicting perceptions and negative emotions. This inconsistency can lead to error signals in the brain.

*Expectation violation* theory posits that androids violate our expectations about how other people should look and behave. When these expectations are not met, *discomfort* and *disgust* can occur.

The uncanny valley effect can also be influenced by specific cultural factors, such a. Acceptance of robots can vary across cultures and lifespans. In particular, *religious beliefs and thoughts* have been suggested as a source of aversion to human-like robot design. Abrahamistic followers, for example, could perceive that a human-like android as an offense to the divine dignity of the human body plan. To the opposite, it has been suggested that human-like robots remind people of their own mortality or the fact that they are just biological machines.





### Innateness

Opposed to the socialization theories, a number of theories see the cause of the UV effect in innate cognitive structures that have evolved by evolution and as such are attributes of the human body plan. These theories fall into two classes, strictly *evolutionary theories* link the effect directly to reproduction fitness. *Cognitive theories* assume innate structures, but leave the possibility of an undesired side effect that persists, because it has *no effect* on reproduction fitness. 

According to evolutionary theories, the uncanny valley effect is tightly linked to encountering threats and basic emotions such as *fear*, *disgust*, and *aversion*. Studies have shown that eeriness is associated with these emotions, with fear playing a particularly important role. The uncanny valley effect could also be a type of *survival instinct* that warns us of potential threats such as sick or dead bodies.





### Cognitive theories

*Perceptual dissonance theory* posits that the feeling of uncanny occurs when there is a contradiction between what one sees and what one expects. This could be caused by contradictory sensory information or unexpected behavior.

The *perceptual magnet effect* describes the tendency for stimuli that are near a category boundary to be perceived as more dissimilar than stimuli that are within a category. *Conflicting cues* can lead to perceptual tension at category boundaries, which is experienced as discomfort.

*Processing Fluency* theory states that cognitive effort generally is perceived as negative. A typical finding in this regard is that humans are biased towards familiar stimuli, because recognition is cognitive less demanding than seeing something for the first time. Processing fluency has experimentally been shown across a wide range of modalities, [including faces?], Several theories mentioned before involve some kind of uncertainty or even conflict, which is just what processing fluency theory predicts to produce negative feelings. While processing fluency may explain the negative valence of the the UV effect in conjunction with more specific theories, it still falls short in two respects: First, it does not explain the specific sensation of eeriness, which is described very differently to, say, mental fatigue. Second, it does not answer the question which features of robot faces specifically cause the cognitive effort in a near human-like face.



### Face perception

Compared to higher cognitive skills, there is very little variation in how well and how fast people can recognize faces. Faces are known as visual stimuli with maximum salience for all humans, except for some individuals far on the neuro-diverse continuum. During childhood development, faces are the first complex visual stimuli to be learned and some see this as the onset of social development per se. The argument can be made that fast processing is an indicator that UVE occurs during face processing.

Already David Hume recognized the human bias to see faces in figures that only remotely resemble a face. In terms of signal detection, face recognition is tuned to avoid misses, at the expense of a high false alarms rate.  It only takes an arc and two dots contained in a circle to evoke the sensation of a face.

Face recognition is a multiple stages process. In the first stage (<100ms), general features of the image, like edges, contrasts and basic forms are processed. This is followed by the a specific activation for face forms, taking place between 100 - 200ms. In 200 - 300ms a detected face is processed for emotional and social information. After 300ms already, conscious processing starts, for example identifying a person. Supposed, that early visual processing itself is responsible for the UVE, the effect is most likely to occur after 200ms (specific face processing) or after 300ms (information extraction).


### Biological faces

Evolutionary theories on the UVE emphasize a specific link to reproduction fitness, whereas cognitive theories leave the possibility that it is a mostly harmless side effect of some other cognitive structures that are vital. 

Speculating about evolutionary origins of the Uncanny Valley effect on robot faces is futile insofar as at time of evolution robots were not part of the environment of humans. It is impossible that robots exerted  evolutionary pressure. Instead, biological faces of all kinds were part of the environment and strong mechanisms to discern one's own species has evolved in humans (and in most species having sex or more advanced forms of social life).

Steckenfinger and Ghazanfar (2009) investigated whether Macaque monkeys (Macaca fascicularis) exhibit the uncanny valley effect. The monkeys were presented with three different types of faces: real monkey faces, realistic synthetic agent faces, and unrealistic synthetic agent faces. The results showed that the monkeys looked longer at the unrealistic synthetic faces and the real faces than at the realistic synthetic faces. This result suggests that the monkeys experience the UV effect, supporting the idea that this effect may be based on evolutionary mechanisms that are not unique to humans.

The possibility exists, that at one point in evolution, homo sapiens ancestors were surrounded by other species with very similar features, such that a more very fine-tuned mechanism evolved to avoid false alarms at the fringe. In the present study, we were also using a sample of biological faces. If the effect can be replicated with biological faces, this would contradict all theories positing that the effect is a culturally formed reaction towards robots. Instead, finding the Uncanny Valley in biological faces would directly support theories positing evolutionary origins.


## Research questions


1. When in the cognitive processing chain does the Uncanny Valley effect happen?

A common experimental method to home in on the cognitive mechanisms responsible for a behavioral effect is the manipulation of presentation times, where the ongoing processing of a stimuli  is interrupted by a visual mask. The shortest presentation time necessary to produce the Uncanny Valley effect is an indication  of which cognitive processes could possibly be involved.
Finding the Uncanny Valley effect in the pre-conscious stages (< 300ms) would contradict all theories involving conscious processing, such identifying a face, assessing danger or having religious thoughts. Finding the effect to occur between 100ms - 200ms would strongly support the idea that early face processing is the culprit. Even shorter minimum processing times (<100ms) would be a surprise, as this would be before specific face processing.


2. Is the observed effect universal?

While fast processing is an indicator for innate cognitive functions, it alone is not sufficient to assume innateness. Many cognitive functions that are acquired throughout a life time can become automated and fast. What really sets innate perceptual mechanisms apart is the absence of individual differences. The present study replicates the original M&R experiment, but uses many more trials per participant. This allows to estimate individual response curves and use calculus to derive measures for universality.

3. Is the observed effect resistant to habituation?

Another strong indicator for pre-attentional mechanisms is their resistance to habituation. In one experiment a repeated exposure design allows to assess the degree of habituation. This would specifically rule out the mere exposure effect.

4. Can the Uncanny Valley effect be observed in biological faces?

One experiment was conducted to replicate the UVE using realistic biological faces, ranked by human likeness. If biological faces trigger the UVE in the same way, this would contradict all theories assuming that the effect is specific for robots and favor theories that depict the effect as a glitch in cognitive processing. In addition, a succesful replication with biological faces could lead to a fruitful new angle in experimental research on the UVE. 



```{r}
load("")
```


## Methods

```{r}
load("Data/UVA_2.Rda")
```



### Sample

```{r}
UVA_2 |> 
  group_by(Exp, Exposure) |> 
    summarize(N_Obs = n_distinct(Obs),
              n_Part = n_distinct(Part),
              n_Stim = n_distinct(Stim)) |> 
  ungroup()
  
  
```


### Experimental design


### Stimulus design


### Apparatus


### Data analysis

The non-linear relationship between human likeness and emotional reaction postulated by Mori is characterized primarily by two points: The slow rise in the lower human-likeness area is limited by a local maximum (the shoulder), while the lowest point of the valley represents a local minimum (the pit). As M & R have already determined, this curve can be approximated by a cubic polynomial. The advantage of this method is that polynomial functions can be written as a linear concatenation ($b_0 + b_1 x + b_2 x^2 + b_3 x^3$) and can therefore be estimated as linear models. Although the coefficients b_0 to b_3 themselves are not meaningful, the existence and location of the two characteristic points can be determined using differential calculus. 

While a cubic polynomial has a maximum of two stationary points (a local maximum and a local minimum), this is not a necessary result, since quadratic, linear and even constant relationships are special cases of a cubic polynomial, with one and or zero stationary point. The existence of the UVE requires two stationary points, where the minimum follows the maximum. This leads to a practical mathematical definition for the existence of the uncanny valley effect, with the following rules (for ratings):

**R_1**: $f'(x) = 0$  has exactly two solutions $x_1, x_2$, warranting a genuinely cubic polynomial with two stationary points.

**R_2**: $f''(x_1) < 0$ warrants that the left point is the shoulder.

**R_3**: $0 < x_1$ and $x_2 < 1$ warrants that both points are in the observed range of human-likeness (on a scale from Zero to One).

In an extension of the original experiment, participants rated all stimuli in the set and by estimating multi-level polynomial models, we obtained individual curves. Using the above rules, for each individual it can be determined whether the effect occurs and at which positions the stationary points are located. 
Furthermore, Bayesian MCMC sampling allows to apply this procedure to every MCMC sample, we were able to 

+ measure the probability that the uncanny valley effect occurs per individual
+ determine the variance in the location of stationary points, where lower variance means less individual differences. 

A multi-variate generalized multi-level polynomial regression was estimated with the following predictor term:

```{r}
outcome ~  0 + (Exposure:repeated:biological:poly(hum_like, 3)) 
             + ((repeated:Exposure:biological:poly(hum_like, 3))|Part)
```

where:

+ *outcome* is ratings or response times
+ *Exposure* is the used presentation time of 33, 50, 100, 200 or 2000ms
+ *repeated* is how often the same stimulus has been encountered before
+ *(...)|Part* is the participant-level random effects

Ratings were translated to the open interval (0;1) to be amenable for Beta regression. For response times, an ExGaussian response distribution was used, with an identity link function. In addition to the mean predictor term, participant-level family parameters were estimated. Especially with rating scales, this can accommodate a wide range of response patterns. Prior visual screening revealed that some peculiar patterns exist especially in rating scale data. Among the observed patterns were dichotomous response patterns and  participants that fell into a 5-bins or 7-bins pattern despite the visual analog scale.

We made use of Bayesian regression by MCMC sampling, which allows to derive quantities that can be treated the same way as linear coefficients, e.g. deriving credibility intervals or testing hypotheses. For the purpose of universality testing, the stated rules were applied on the level of MCMC draws, which allowed us to create a test statistic representing the posterior probability, that a participant experiences the UVE under the given circumstances (stimuli set, presentation time, repeated exposure).


## Results

```{r}
load("Data/UVA_2.Rda")
```


```{r fig.height=8, fig.asp=1.5}
UVA_2 |> 
  ggplot(aes(x = hum_like, y = neeriness)) +
  facet_grid(Exp ~ 1, scales = "free_y") +
  geom_smooth(aes(y = neeriness, col = Exposure, linetype = as.factor(repetition)))
  #             method = "lm", formula = y ~ poly(x, 3), se = T)
  # geom_smooth(aes(y = neeriness, color = "neeriness"), 
  #             method = "lm", formula = y ~ poly(x, 3), se = T) +
  # geom_smooth(aes(y = rt, color = "RT"), 
  #             method = "lm", formula = y ~ poly(x, 3), se = T) +
  # labs(colour = "Outcome")
```




Eeriness ratings and response times seen together:

Neeriness ratings show a very similar pattern for short exposures: a flat line for human-likeness below 60%, then rising. Only with long exposures does the effect appear in the ratings. Whatever subconscious mechanism is at play in the Uncanny valley, ratings need the *extra exposure time* for becoming aware of the disturbance, or at least *high salience*.

Given the experimental setup, where fast responses where *not* enforced in any way, the interpretation of longer response times is *undecisiveness*.
In all conditions, response times start to rise at around 25%. This most likely is the point where a robot face fulfills the "Smiley" requirements to trigger face recognition. First *at 50ms a local maximum* appears for exposures up to 300ms. It is located at around 75%, which is congruent with the local minimum of ratings in long exposure. This indicates that the cognitive disturbance already kicks in at around 50ms -- which is deep in the pre-attentional phase -- and manifests itself as longer response times. 
 

### Polynomial regression

```{r echo = F, eval = F}

UVA_4 <- 
  UVA_2 |> 
  filter(Exp %in% c("PS", "RK")) |> 
  mutate(rt = if_else(rt > 5, NA, rt)) |> 
  #filter((as.numeric(Part) %% 3) == 0 ) |> 
  mutate(hl_0 = 1, hl_1 = hum_like, hl_2 = hum_like^2, hl_3 = hum_like^3) |> 
  bayr::as_tbl_obs()

```



```{r}

M_0 <- stan_glmer(neeriness ~ 0 + (Exposure : (hl_0 + hl_1 + hl_2 + hl_3)) +
                     ((Exposure : (hl_0 + hl_1 + hl_2 + hl_3))|Part), 
                       data = UVA_4, chains = 4)
#summary(M_0)
PP_0 <- post_pred(M_0, thin = 10)
save(M_0, PP_0, UVA_4, file = "M_0.Rda")


M_1 <- stan_glmer(rt ~ 0 + (Exposure : (hl_0 + hl_1 + hl_2 + hl_3)) +
                     ((Exposure : (hl_0 + hl_1 + hl_2 + hl_3))|Part), 
                       data = UVA_4, chains = 4)
#summary(M_1)
PP_1 <- post_pred(M_1, thin = 10)
save(M_1, PP_1, UVA_4, file = "M_1.Rda")

```


```{r}
T_pred <- 
  bind_rows(PP_0, PP_1) |> 
  predict() |> 
  left_join(UVA_4, by = "Obs") |> 
  mutate(Outcome = if_else(model == "M_0", "Neeriness", "RT"))

```



```{r fig.width = 12, fig.height = 24}
T_pred |> 
  filter(center >= 0 & center <= 15) |> 
  ggplot(aes(x = hum_like, color = Exposure, y = center)) +
  #facet_wrap(~Part) +
  #geom_point()
  facet_grid(Outcome ~ Exposure, scales = "free_y") +
  geom_smooth(aes(group = Part), se = F)

```

```{r}
M_1 <- stan_glmer( neeriness ~ 0 + (Exposure : poly(hum_like, 3)) 
                    + ((Exposure : poly(hum_like, 3))|Part), data = UVA_2)

PP_1 <- post_pred(M_1, thin = 10)

save(M_1, PP_1, UVA_2, file = "M_1.Rda")


```


```{r echo = F, eval = F}
## BRMS multivariate (veery slow!)
F_2 <- bf(mvbind(neeriness, rt) ~  0 + (Exposure : (hl_0 + hl_1 + hl_2 + hl_3)) +
            ((Exposure : (hl_0 + hl_1 + hl_2 + hl_3))|Part)) +
            set_rescor(TRUE)

M_2 <- brm(F_2, data = UVA_4)
```



### Stationary Points

Population level

```{r}
#load("M_0.Rda")
#load("M_1.Rda")
#rm(PP_0, PP_1)
#P_0 <- bind_rows(posterior(M_0), posterior(M_1))
#rm(M_0, M_1)
#save(P_0, file = "P_0.Rda")

load("P_0.Rda")
P_stat <- P_0 |> re_scores() 
rm(P_0)

dim(P_stat)
colnames(P_stat)


P_mini <- P_stat |> filter(iter %% 100 == 0 &
                            fixef != "Intercept" ) 

P_uncanny <- 
  P_mini%>%
    as_tibble() |> 
    mutate( fixef = str_replace(fixef, "Exposure", "")) |>
    #mutate( fixef = str_replace(fixef, "hl_", "")) |>
    mutate(Outcome = if_else(model == "M_0", "Neeriness", "RT")) |> 
    separate_wider_delim(fixef, ":", names = c("Exposure", "Poly")) |>
    select(Outcome, iter, Part = re_entity, Exposure, Poly, value) %>%
    pivot_wider(names_from = "Poly", values_from = "value") |> 
    rowwise() |> 
    mutate( trough = uncanny::trough(c(hl_0, hl_1, hl_2, hl_3)),
            shoulder = uncanny::shoulder(c(hl_0, hl_1, hl_2, hl_3)),
            has_trough = !is.na(trough),
            has_shoulder = !is.na(shoulder),
            shoulder_left = trough > shoulder,
            is_uncanny = has_trough & has_shoulder & shoulder_left,
            is_inv_uncanny = has_trough & has_shoulder & !shoulder_left,
            disconfirm = !is_uncanny & 
                         !(is_inv_uncanny & Exposure != "2000ms" & Outcome == "RT")) |> 
  mutate(Exposure = forcats::fct_reorder(Exposure, c()))
```

```{r}
P_uncanny |> 
  group_by(Part, Exposure, Outcome) |> 
  summarize(is_uncanny = mean(is_uncanny), 
            is_inv_uncanny = mean(is_inv_uncanny), 
            disconfirm = mean(disconfirm)) |> 
  ungroup() |> 
  ggplot(aes(x = Exposure, color = Outcome, y = disconfirm)) +
  geom_boxplot() +
  ylim(0,1)
```



```{r }
T_Uncanny <- 
  P_uncanny |> 
    mutate(Exposure = forcats::fct(Exposure, c("50ms","100ms","200ms","2000ms"))) |> 
    mutate(first_turn = if_else(shoulder_left, shoulder, trough),
           second_turn = if_else(shoulder_left, trough, trough)) |> 
    pivot_longer(first_turn:second_turn, names_to = "Stat_point") |>
    group_by(Part, Exposure, Outcome, Stat_point) |> 
    summarize(center = median(value, na.rm = T),
              lower = quantile(value, .025, na.rm = T),
              upper = quantile(value, .975, na.rm = T),
              evidence = 1 - mean(disconfirm)) |> 
    ungroup()


T_Uncanny |> 
  ggplot(aes(x = Stat_point, 
             y = center, ylim = lower, ymax = upper, 
             fill = Exposure,
             alpha = evidence)) +
  geom_violin() +
  facet_grid(~Outcome) +
  ylim(0,1)


```



## Discussion

Overall, the UVE appears to be universal and fast. 


The following conclusions can be drawn from the model and the data:

1. If we accepts responses times as decision times, the UVE produces a higher degree of uncertainty in the eeriness ratings.
2. The Uncanny Valley effect starts to appear at 50ms which is still dominated by visual processing.
3. In the ratings the effect starts to appear at 200ms. probably it just takes that much time to realize the disturbancce.




### Limitations



 






